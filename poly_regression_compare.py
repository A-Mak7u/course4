import pandas as pd
import joblib
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.preprocessing import PolynomialFeatures
from tqdm import tqdm
import matplotlib.pyplot as plt

DATA_PATH = "final_2013_2023_T_ERA5_LST_daynight.csv"
MODEL_PATH = "outputs_runs/20250905_142927/xgb_model.pkl"

df = pd.read_csv(DATA_PATH)

for col in ["Temperature_2m", "Dewpoint_2m"]:
    if col in df.columns:
        df[col] = df[col] - 273.15

df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
df["year"] = df["Date"].dt.year

features = [c for c in df.columns if c not in ["Cod", "Date", "year", "T"]]
df = df.dropna(subset=["T"])
X = df[features].fillna(-999)
y = df["T"]

top_features = [
    "Temperature_2m", "Evaporation", "LST_Day", "Dewpoint_2m",
    "LST_Night", "Surface_pressure", "X_final", "Y_final", "Total_precipitation"
]
X_top = X[top_features]

degrees = [1, 2, 3]
results = []

for degree in tqdm(degrees, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–∏–Ω–æ–º–æ–≤"):
    poly = PolynomialFeatures(degree=degree, include_bias=False)
    X_poly = poly.fit_transform(X_top)

    model = LinearRegression()
    model.fit(X_poly, y)
    y_pred = model.predict(X_poly)

    r2 = r2_score(y, y_pred)
    n_terms = X_poly.shape[1]

    results.append((degree, r2, n_terms))

    print(f"\nüìä –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å—Ç–µ–ø–µ–Ω–∏ {degree}")
    print(f"R¬≤ = {r2:.4f}, —á–∏—Å–ª–æ —á–ª–µ–Ω–æ–≤ = {n_terms}")
    feature_names = poly.get_feature_names_out(top_features)
    for f, c in zip(feature_names[:15], model.coef_[:15]):
        print(f"{f}: {c:.4f}")
    if len(feature_names) > 15:
        print("... (–æ–±—Ä–µ–∑–∞–Ω–æ, –≤—Å–µ–≥–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤:", len(feature_names), ")")
    print("–°–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω:", model.intercept_)

fig, ax1 = plt.subplots(figsize=(7, 5))

ax2 = ax1.twinx()
degrees_list = [d for d, _, _ in results]
r2_list = [r for _, r, _ in results]
terms_list = [n for _, _, n in results]

ax1.plot(degrees_list, r2_list, "o-r", label="R¬≤")
ax2.plot(degrees_list, terms_list, "o-b", label="–ß–∏—Å–ª–æ —á–ª–µ–Ω–æ–≤")

ax1.set_xlabel("–°—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞")
ax1.set_ylabel("R¬≤", color="r")
ax2.set_ylabel("–ß–∏—Å–ª–æ —á–ª–µ–Ω–æ–≤", color="b")

plt.title("–°–ª–æ–∂–Ω–æ—Å—Ç—å —É—Ä–∞–≤–Ω–µ–Ω–∏—è vs –¢–æ—á–Ω–æ—Å—Ç—å")
plt.tight_layout()
plt.savefig("poly_regression_comparison.png")
plt.close()

print("\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ poly_regression_comparison.png")
